#!/usr/bin/perl

# Copyright © 1998 Richard Braakman
# Copyright © 2008 Frank Lichtenheld
# Copyright © 2008, 2009 Russ Allbery
# Copyright © 2014 Niels Thykier
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, you can find it on the World Wide
# Web at http://www.gnu.org/copyleft/gpl.html, or write to the Free
# Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
# MA 02110-1301, USA.

# The harness for Lintian's test suite.  For detailed information on
# the test suite layout and naming conventions, see t/tests/README.
# For more information about running tests, see
# doc/tutorial/Lintian/Tutorial/TestSuite.pod
#

use strict;
use warnings;
use autodie;
use Carp qw(confess);
use Cwd();

use File::Path qw(make_path);
use File::Spec::Functions qw(abs2rel rel2abs splitpath splitdir);
use Getopt::Long qw(GetOptions);
use IO::Async::Channel;
use IO::Async::Loop;
use IO::Async::Routine;

use constant SUITES => qw(scripts changes debs source tests);

our ($LINTIAN_ROOT, $LINTIAN, @LINTIAN_CMD, @LINTIAN_COMMON_OPTIONS);

BEGIN {
    # Whitelist the part of the environment we permit.  This is to
    # avoid inheriting things that messes up tests (like CFLAGS,
    # DH_OPTIONS, DEB_HOST_ARCH etc.)
    my $dplint;
    my %PRESERVE_ENV = map { $_ => 1 } qw(
      LINTIAN_TEST_INSTALLED
      NO_PKG_MANGLE
      PATH
      TMPDIR
    );
    # TODO: MAKEFLAGS - some of the tests don't cope too well with it
    for my $key (keys(%ENV)) {
        delete $ENV{$key}
          if not exists($PRESERVE_ENV{$key});

    }
    for my $var (sort(keys(%ENV))) {
        print "ENV[$var]=$ENV{$var}\n";
    }

    if (($ENV{'LINTIAN_TEST_INSTALLED'}//'no') eq 'yes') {
        $LINTIAN_ROOT = '/usr/share/lintian';
        $LINTIAN = '/usr/bin/lintian';
        $dplint = '/usr/share/lintian/frontend/dplint';
    } else {
        $LINTIAN_ROOT = Cwd::cwd();
        $LINTIAN = "$LINTIAN_ROOT/frontend/lintian";
        $dplint = "$LINTIAN_ROOT/frontend/dplint";
    }
    $ENV{'LINTIAN_ROOT'} = $LINTIAN_ROOT;
    $ENV{'LINTIAN_TEST_ROOT'} = $LINTIAN_ROOT;
    $ENV{'LINTIAN_FRONTEND'} = $LINTIAN;
    $ENV{'LINTIAN_DPLINT_FRONTEND'} = $dplint;
    @LINTIAN_CMD = ($LINTIAN);

    # Ubuntu auto-builders run pkg-mangle which messes with our
    # test packages, so ask it not to do so by default.
    $ENV{'NO_PKG_MANGLE'} = 'true'
      unless exists($ENV{'NO_PKG_MANGLE'});

    $ENV{'LC_ALL'} = 'C';

    # Set standard umask because many of the test packages rely on this
    # when creating files from the debian/rules script.
    umask(022);
}

use lib "$LINTIAN_ROOT/lib";

use Lintian::Command qw(safe_qx);
use Lintian::Internal::FrontendUtil qw(default_parallel);
use Lintian::Util qw(delete_dir internal_error parse_boolean
  rstrip slurp_entire_file touch_file);

use Test::Lintian::Harness
  qw(chdir_runcmd check_test_depends find_tests_for_tag
  runsystem runsystem_ok skip_reason up_to_date);
use Test::Lintian::ConfigFile qw(read_config);
use Test::Lintian::Filter qw(find_selected_lintian_testpaths);
use Test::Lintian::Helper qw(copy_dir_contents);
use Test::Lintian::Prepare qw(prepare);
use Test::State;

our $STANDARDS_VERSION = '4.2.1';
our $ARCHITECTURE = safe_qx(qw(dpkg-architecture -qDEB_HOST_ARCH));
my $RUNNER_TS = (stat($0))[9];
chomp $ARCHITECTURE;

my $DATE = safe_qx(qw(date -R));
chomp $DATE;

my $output_is_tty = -t STDOUT;

our $IO_LOOP = IO::Async::Loop->new;

# --- Parsed options / arguments

our $VERBOSE = 0;
our ($RUNDIR, $TESTSET, $ALWAYS_REBUILD);
our $JOBS = -1;
our $DUMP_LOGS = 1;
our @TESTS;
our $ACTIVE_JOBS = 0;

my ($run_all_tests, $tag, $coverage, $test_filter, %suites);

parse_args();

if (-d "$TESTSET/helpers/bin") {
    # Add the test helpers to PATH
    my $tpath = Cwd::abs_path("$TESTSET/helpers/bin");
    internal_error("Cannot resolve $TESTSET/helpers/bin: $!") unless $tpath;
    $ENV{'PATH'} = "$tpath:$ENV{'PATH'}";
}

# --- Display output immediately
STDOUT->autoflush;

# --- Exit status for the test suite driver

# Exit codes:
# 0 - success
# 1 - one or more tests failed
# 2 - an error prevented proper running of the tests
my $status = 0;

# Tests that were skipped and why
# - $suite => $testname => $reason
my %skipped;
# Tests that failed
my @failed;

# If we don't run any tests, we'll want to warn that we couldn't find
# anything.
my $tests_run = 0;

# find test paths
my @testpaths = find_selected_lintian_testpaths($TESTSET, $test_filter);

@TESTS = map { read_desc("$_/desc") } @testpaths;

if ($test_filter && $test_filter =~ s/^tag://) {
    $tag = $test_filter;
    # clear test_filter to avoid find a "single" test.
    $test_filter = '';
} elsif ($test_filter && $test_filter =~ m/^suite:(.++)/) {
    my $list = $1;
    %suites = ();
    foreach my $s (split m/\s*+,\s*+/, $list) {
        $suites{$s} = 1;
    }
    # clear singletest to avoid find a "single" test.
    $test_filter = '';
} else {
    # run / check all of them
    foreach my $s (SUITES) {
        $suites{$s} = 1;
    }
}

if (!$tag) {
    run_prove_tests();
}

if (@TESTS) {
    for (0..$JOBS-1) {
        create_child($IO_LOOP, \@TESTS)
          or last;
    }

    $IO_LOOP->run;
}

print_test_summary();

exit $status;

sub parse_args {
    my ($debug);
    Getopt::Long::Configure('bundling');
    GetOptions(
        'B'            => \$ALWAYS_REBUILD,
        'd|debug+'     => \$debug,
        'j|jobs:i'     => \$JOBS,
        'k|keep-going' => \$run_all_tests,
        'dump-logs!'   => \$DUMP_LOGS,
        'v|verbose'    => \$VERBOSE,
        'coverage:s'   => \$coverage,
        'help|h'       => sub {usage(0); },
    ) or usage();

    if (@ARGV < 2 || @ARGV > 3) {
        usage();
    }

    $VERBOSE = 1 + $debug if $debug;

    ($TESTSET, $RUNDIR, $test_filter) = @ARGV;

    if (-d $RUNDIR) {
        my $abs = Cwd::abs_path($RUNDIR);
        internal_error("Cannot resolve $RUNDIR: $!")
          if not defined($abs);
        $RUNDIR = $abs;
    } else {
        internal_error("test directory $RUNDIR does not exist");
    }

    unless (-d $TESTSET) {
        internal_error("test set directory $TESTSET does not exist");
    }

    $TESTSET = rel2abs($TESTSET);

    if (defined($coverage)) {
        my $harness_perl_switches = $ENV{'HARNESS_PERL_SWITCHES'}//'';
        # Only collect coverage for stuff that D::NYTProf and
        # Test::Pod::Coverage cannot do for us.  This makes cover use less
        # RAM in the other end.
        my @criteria = qw(statement branch condition path subroutine);
        my $coverage_arg
          = '-MDevel::Cover=-silent,1,+ignore,^(.*/)?t/scripts/.+';
        $coverage_arg .= ',+ignore,/usr/bin/.*,+ignore,(.*/)?Dpkg';
        $coverage_arg .= ',-coverage,' . join(',-coverage,', @criteria);
        $coverage_arg .= ',' . $coverage if $coverage ne '';
        $ENV{'LINTIAN_COVERAGE'} = $coverage_arg;
        $harness_perl_switches .= ' ' . $coverage_arg;
        $ENV{'HARNESS_PERL_SWITCHES'} = $harness_perl_switches;
        # Coverage has some race conditions (at least when using the same
        # cover database).
        push(@LINTIAN_COMMON_OPTIONS, '-j1');
    }

    # Getopt::Long assigns 0 as default value if none was specified
    # (i.e. "-j").  Otherwise, $JOBS can also be -1 if "-j" was not
    # specified at all.
    if ($JOBS <= 0) {
        $JOBS = default_parallel();

        print "Doing up to $JOBS concurrent builds/tests\n"
          if $VERBOSE >= 2;
    }

    return;
}

sub print_test_summary {
    if (!$tests_run) {
        if ($test_filter) {
            print "W: No tests run, did you specify a valid test name?\n";
        } elsif ($tag) {
            print "I: No tests found for that tag.\n";
        } else {
            print
              "E: No tests run, did you specify a valid testset directory?\n";
        }
    } else {
        if (%skipped) {
            print "\nSkipped/disabled tests:\n";
            for my $suite (SUITES) {
                if (exists($skipped{$suite})) {
                    print "  [$suite]\n";
                    for my $testname (sort(keys(%{ $skipped{$suite} }))) {
                        my $reason = $skipped{$suite}{$testname};
                        print "    $testname: $reason\n";
                    }
                }
            }
        }
        if (my $number = @failed) {
            print "\nFailed tests ($number)\n";
            for my $test (@failed) {
                print "    $test\n";
            }
        }
    }
    return;
}

sub run_lintian {
    my ($test_state, $testdata, $file, $rundir, $out) = @_;
    $test_state->progress('testing');
    my @options = split(' ', $testdata->{options}//'');
    unshift(@options, '--allow-root', '--no-cfg');
    unshift(@options, '--profile', $testdata->{profile});
    unshift(@options, '--no-user-dirs');
    if (my $incl_dir = $testdata->{'lintian_include_dir'}) {
        unshift(@options, '--include-dir', $incl_dir);
    }
    my $pid = open(my $in, '-|');
    if ($pid) {
        my @data = <$in>;
        my $status = 0;
        eval {close($in);};
        if (my $err = $@) {
            internal_error("close pipe: $!") if $err->errno;
            $status = ($? >> 8) & 255;
        }
        if (defined($coverage)) {
            # Devel::Cover causes some annoying deep recursion
            # warnings.  Filter them out, but only during coverage.
            # - This is not flawless, but it gets most of them
            @data = grep {
                !m{^Deep [ ] recursion [ ] on [ ] subroutine [ ]
                    "[^"]+" [ ] at [ ] .*B/Deparse.pm [ ] line [ ]
                   \d+}xsm
            } @data;
        }
        unless ($status == 0 or $status == 1) {
            my $name = $testdata->{testname};
            #NB: lines in @data have trailing newlines.
            my $msg = "$LINTIAN @options $file exited with status $status\n";
            $msg .= join(q{},map { "$name: $_" } @data);

            die $msg;
        } else {
            @data = sort @data if $testdata->{sort} eq 'yes';
            open(my $fd, '>', $out);
            print $fd $_ for @data;
            close($fd);
        }
    } else {
        my @cmd = @LINTIAN_CMD;
        if ($ENV{'LINTIAN_COVERAGE'}) {
            my $suite = $testdata->{suite};
            my $name = $testdata->{testname};
            my $cover_dir = "./cover_db-${suite}-${name}";
            $ENV{'LINTIAN_COVERAGE'} .= ",-db,${cover_dir}";
            unshift(@cmd, 'perl', $ENV{'LINTIAN_COVERAGE'});
        }
        open(STDERR, '>&', \*STDOUT);
        chdir($rundir);
        exec @cmd, @options, @LINTIAN_COMMON_OPTIONS, $file
          or internal_error("exec failed: $!");
    }
    return 1;
}

# generic_runner
#
# Runs the test called $test assumed to be located in $TESTSET/$dir/$test/.
#
sub generic_runner {
    my ($test_state, $testdata) = @_;
    my $suite = $testdata->{suite};
    my $testname = $testdata->{testname};
    my $testdir = "$TESTSET/$suite/$testname";

    my $targetdir = "$RUNDIR/$suite/$testname";
    my $stampfile = "$RUNDIR/$suite/$testname-build-stamp";

    # get lintian subject
    die 'Could not get subject of Lintian examination.'
      unless exists $testdata->{build_product};
    my $subject = "$targetdir/$testdata->{build_product}";

    if ($ALWAYS_REBUILD or not up_to_date($stampfile, $testdir, $RUNNER_TS)) {

        $test_state->progress('building');

        if (exists $testdata->{build_command}) {
            my $command
              = "cd $targetdir; $testdata->{build_command} > ../build.$testname 2>&1";
            if (system($command)) {
                $test_state->dump_log("${RUNDIR}/${suite}/build.${testname}")
                  if $DUMP_LOGS;
                die "$command failed.";
            }
        }

        die 'Build was unsuccessful.'
          unless -f $subject;

        touch_file($stampfile);
    } else {
        $test_state->progress('building (cached)');
    }

    my $pkg = $testdata->{source};

    run_lintian($test_state, $testdata, $subject, $targetdir,
        "$targetdir/tags.$pkg");

    # Run a sed-script if it exists, for tests that have slightly variable
    # output
    if (-f "$targetdir/post_test") {
        runsystem_ok('sed', '-ri', '-f', "$targetdir/post_test",
            "$targetdir/tags.$pkg");
        if ($testdata->{'sort'} eq 'yes') {
            # Re-sort as the sed may have changed the order lines
            open(my $rfd, '<', "$targetdir/tags.$pkg");
            my @lines = sort(<$rfd>);
            close($rfd);
            open(my $wfd, '>', "$targetdir/tags.$pkg");
            print {$wfd} $_ for @lines;
            close($wfd);
        }
    }

    my $expected = "$testdir/tags";
    my $origexp = $expected;

    if (-x "$targetdir/test_calibration") {
        my $calibrated = "$targetdir/expected.$pkg.calibrated";
        $test_state->progress('test_calibration hook');
        runsystem_ok(
            "$targetdir/test_calibration", $expected,
            "$targetdir/tags.$pkg", $calibrated
        );
        $expected = $calibrated if -e $calibrated;
    }

    _check_result($test_state, $testdata, $expected,
        "$targetdir/tags.$pkg",$origexp);

    return;
}

sub read_desc {
    my ($path) = @_;

    my $testdata = read_config($path);

    # needed for suite calculation
    my $depth = scalar splitdir((splitpath($TESTSET))[1]);

    # calculate suite from path
    my $suite = (splitdir((splitpath($path))[1]))[$depth];

    # add suite to data
    $testdata->{suite} = $suite;

    my $defaults = read_config("$TESTSET/defaults/desc");

    foreach my $key (keys %{$defaults}) {
        $testdata->{$key} = $defaults->{$key}
          unless exists $testdata->{$key};
    }

    return $testdata;
}

sub run_prove_tests {
    my @do_run;
    if ($test_filter) {
        for my $part (split(m/,/, $test_filter)) {
            my $script = "$TESTSET/scripts/${part}.t";
            if (-f $script) {
                push(@do_run, $script);
            } elsif (-d "$TESTSET/scripts/${part}") {
                push(@do_run, "$TESTSET/scripts/${part}");
            }
        }
    } elsif ($suites{'scripts'}) {
        unless (-d "$TESTSET/scripts") {
            internal_error("cannot find $TESTSET/scripts: $!");
        }
        @do_run = ("$TESTSET/scripts");
    }
    if (@do_run) {
        my $jobs = $JOBS;
        # Devel::Cover + one cover_db + multiple processes is a recipe
        # for corruptions.  Force $jobs to 1 if we are running under
        # coverage.
        $jobs = 1 if $ENV{'LINTIAN_COVERAGE'};
        my @prove_cmd= ('prove', '-j', $jobs, '-r', '-I', "$LINTIAN_ROOT/lib");

        print "Test scripts:\n";
        if (system(@prove_cmd, @do_run) != 0) {
            exit 1 unless $run_all_tests;
            push(@failed, "suite:scripts [Try: prove -lr -j$JOBS t]");
            $status = 1;
        }
        $tests_run++;

        print "\n";
    }
    return;
}

sub create_child {
    my ($loop, $tests) = @_;
    my ($child_in_ch, $child_out_ch, $routine);
    my $start_test = shift(@{$tests});

    # If there are no more tests, don't spawn a routine for it
    # Usually happens when only running a single thread.
    return if not defined($start_test);

    $child_in_ch = IO::Async::Channel->new;
    $child_out_ch  = IO::Async::Channel->new;

    $routine = IO::Async::Routine->new(
        channels_in  => [$child_in_ch],
        channels_out => [$child_out_ch],

        code => sub {
            $0 = 'Test worker - idle';
            while (my $test_data = $child_in_ch->recv) {
                my $state = Test::State->new($test_data, $child_out_ch);
                my $suite = $test_data->{'suite'};
                my $testname = $test_data->{testname};

                $0 = "Test worker - processing ${suite}::${testname}";

                my $retval;
                eval {
                    $retval= prepare(
                        $state, $test_data,
                        $RUNDIR, $TESTSET,
                        $RUNNER_TS, $ALWAYS_REBUILD,
                        $ARCHITECTURE,$STANDARDS_VERSION,
                        $DATE
                    );
                };
                if (my $err = $@) {
                    $state->test_error($err);
                }else {
                    unless ($retval) {
                        eval { generic_runner($state, $test_data); };
                        if (my $err = $@) {
                            $state->test_error($err);
                        }
                    }
                }

                $0 = 'Test worker - idle';

                #                my $testname = $ref->{'testname'};
                #                print STDERR "$child_no: $suite::$testname\n";
                # Can only send references
                #                $child_out_ch->send( $ref );
            }
            return;
        },

        on_finish => sub {
            $ACTIVE_JOBS--;
            if ($ACTIVE_JOBS < 1) {
                print "Stopping loop, no more active workers\n"
                  if $VERBOSE >= 2;
                $loop->stop;
            }
            return;
        },
    );

    $loop->add($routine);
    $ACTIVE_JOBS++;
    $child_in_ch->send($start_test);

    $child_out_ch->configure(
        'on_recv' => sub {
            my (undef, $from_child) = @_;
            handle_msg_from_child($child_in_ch, $tests, @{$from_child});
            return;
        },
    );
    return 1;
}

my $partial_line = 0;  ## no critic (it is reachable)

sub handle_msg_from_child {
    my ($child_in_ch, $test_queue, $msg_type, $test_metadata, @payload) = @_;
    my $suite = $test_metadata->{'suite'};
    my $testname = $test_metadata->{'testname'};

    if ($VERBOSE >= 3) {
        my @dmsg = map { $_ // '<undef>' } @payload;
        print
          "PROTO-MSG [DEBUG] ${msg_type} -- ${suite}::${testname} [@dmsg]\n";
    }

    if (   $msg_type eq 'pass'
        or $msg_type eq 'skip'
        or $msg_type eq 'fail'
        or $msg_type eq 'error'
        or $msg_type eq 'pass-todo') {
        my $is_problem = ($msg_type eq 'fail' or $msg_type eq 'error');
        my ($info_msg) = @payload;
        my ($test, $final_msg, $show_msg);

        if ($is_problem) {
            push(@failed, "${suite}::${testname}");
            if (not $run_all_tests) {
                # Empty the queue, so no further jobs are started
                $#{$test_queue} = -1;
            }
            $status = 1 if not $status;
        } elsif ($msg_type eq 'skip') {
            $skipped{$suite}{$testname} = $payload[0];
        }
        $final_msg = "${msg_type} ${suite}::${testname}";
        $final_msg .= ": ${info_msg}" if defined($info_msg);
        if (not $output_is_tty and not $VERBOSE) {
            if ($msg_type eq 'pass') {
                $final_msg = '.';
            } elsif ($msg_type eq 'skip') {
                $final_msg = 'S';
            } elsif ($msg_type eq 'pass-todo') {
                $final_msg = 'T';
            } else {
                $show_msg = 1;
            }
        } else {
            $show_msg = 1;
        }
        if ($show_msg) {
            $final_msg .= "\n";
            print "\n" if $partial_line;
            $partial_line = 0;
        } else {
            $partial_line++;
            if ($partial_line > 79) {
                $final_msg .= "\n";
                $partial_line = 0;
            }
        }
        print $final_msg;

        $test = shift(@{$test_queue});

        $tests_run++;
        if (defined($test)) {
            $child_in_ch->send($test);
        } else {
            $child_in_ch->close;
        }
    } elsif ($msg_type eq 'diff-files') {
        my ($original, $actual) = @payload;
        print "\n" if $partial_line;
        $partial_line = 0;
        print "${suite}::${testname}: diff -u ${original} ${actual}\n";
        runsystem_ok('diff', '-u', $original, $actual);
    } elsif ($msg_type eq 'dump-file') {
        my ($log_file) = @payload;
        my $prefix = "${suite}::${testname}: ";
        print "\n" if $partial_line;
        $partial_line = 0;
        handle_dump_log($prefix, $log_file);
    } elsif ($msg_type eq 'progress') {
        my ($new_phase) = @payload;
        print "${suite}::${testname} is now in phase: ${new_phase}\n"
          if $VERBOSE;
    } elsif ($msg_type eq 'log-msg') {
        my ($verbosity, $msg) = @payload;
        if ($verbosity <= $VERBOSE) {
            my $level = 'INFO';
            $level = 'DEBUG' if $verbosity > 1;
            print "INFO-MSG [$level] ${suite}::${testname}: $msg\n";
        }
    }
    return;
}

sub _check_result {
    my ($test_state, $testdata, $expected, $actual, $origexp) = @_;
    # Compare the output to the expected tags.
    my $testok = runsystem_ok('cmp', '-s', $expected, $actual);

    if (not $testok) {
        if ($testdata->{'todo'} eq 'yes') {
            $test_state->pass_todo_test('failed but marked as TODO');
            return;
        } else {
            $test_state->diff_files($expected, $actual);
            $test_state->fail_test('output differs!');
            return;
        }
    }

    unless ($testdata) {
        $test_state->pass_test;
        return;
    }

    # Check the output for invalid lines.  Also verify that all Test-For tags
    # are seen and all Test-Against tags are not.  Skip this part of the test
    # if neither Test-For nor Test-Against are set and Sort is also not set,
    # since in that case we probably have non-standard output.
    my %test_for = map { $_ => 1 } split(' ', $testdata->{'test_for'}//'');
    my %test_against
      = map { $_ => 1 } split(' ', $testdata->{'test_against'}//'');
    if (    not %test_for
        and not %test_against
        and $testdata->{'output_format'} ne 'EWI') {
        if ($testdata->{'todo'} eq 'yes') {
            $test_state->fail_test('marked as TODO but succeeded');
            return;
        } else {
            $test_state->pass_test;
            return;
        }
    } else {
        my $okay = 1;
        my @msgs;
        open(my $etags, '<', $actual);
        while (<$etags>) {
            next if m/^N: /;
            # Some of the traversal tests creates packages that are
            # skipped; accept that in the output
            next if m/tainted/o && m/skipping/o;
            # Looks for "$code: $package[ $type]: $tag"
            if (not /^.: \S+(?: (?:changes|source|udeb))?: (\S+)/o) {
                chomp;
                push(@msgs, "Invalid line: $_");
                $okay = 0;
                next;
            }
            my $tag = $1;
            if ($test_against{$tag}) {
                push(@msgs, "Tag $tag seen but listed in Test-Against");
                $okay = 0;
                # Warn only once about each "test-against" tag
                delete $test_against{$tag};
            }
            delete $test_for{$tag};
        }
        close($etags);
        if (%test_for) {
            if ($origexp && $origexp ne $expected) {
                # Test has been calibrated, check if some of the
                # "Test-For" has been calibrated out.  (Happens with
                # binaries-hardening on some architectures).
                open(my $oe, '<', $expected);
                my %cp_tf = %test_for;
                while (<$oe>) {
                    next if m/^N: /;
                    # Some of the traversal tests creates packages that are
                    # skipped; accept that in the output
                    next if m/tainted/o && m/skipping/o;
                    if (not /^.: \S+(?: (?:changes|source|udeb))?: (\S+)/o) {
                        chomp;
                        push(@msgs, "Invalid line: $_");
                        $okay = 0;
                        next;
                    }
                    delete $cp_tf{$1};
                }
                close($oe);
                # Remove tags that has been calibrated out.
                foreach my $tag (keys %cp_tf) {
                    delete $test_for{$tag};
                }
            }
            for my $tag (sort keys %test_for) {
                push(@msgs, "Tag $tag listed in Test-For but not found");
                $okay = 0;
            }
        }
        if ($okay) {
            if ($testdata->{'todo'} eq 'yes') {
                $test_state->fail_test('marked as TODO but succeeded');
                return;
            }
            $test_state->pass_test;
            return;
        } elsif ($testdata->{'todo'} eq 'yes') {
            $test_state->pass_todo_test(join("\n", @msgs));
            return;
        } else {
            $test_state->fail_test(join("\n", @msgs));
            return;
        }
    }
    confess("Assertion: This should be unreachable\n");
}

sub handle_dump_log{
    my ($prefix, $logf) = @_;
    no autodie qw(open);
    if (open(my $log, '<', $logf)){
        print "${prefix}---- START BUILD LOG\n";
        print "${prefix}$_" while (<$log>);
        print "${prefix}---- END BUILD LOG\n";
        close($log);
    } else {
        print "!!! Could not dump $logf: $!";
    }
    return 1;
}

sub usage {
    my ($exitcode) = @_;
    print <<"END";
Usage: $0 [options] [-j [<jobs>]] <testset-directory> <testing-directory> [<test-selection>]

    --coverage  Run Lintian under Devel::Cover (Warning: painfully slow)
    -d          Display additional debugging information
    --dump-logs Print build log to STDOUT, if a build fails.
    -j [<jobs>] Run up to <jobs> jobs in parallel.
                If -j is passed without specifying <jobs>, the number
                of jobs started is <nproc>+1.
    -k          Do not stop after one failed test
    -v          Be more verbose
    --help, -h  Print this help and exit

    The optional 3rd parameter causes runtests to only run tests that match
    the particular selection.  This parameter can be one of:

      * <testname>
        - Run the test(s) named exactly <testname>.  Note that each suite
          can reuse the name of the test, so this may run more than one
          test.
      * <dir-in-scripts-suite>
        - Run all "scripts"-tests within a given dir.  E.g. "01-critic"
          will run all tests in "t/scripts/01-critic/".
      * <check-name>
        - Run all tests related to the given check.  This is based on the
          name of the test (i.e. it must start with "<check-name>-").
      * legacy
        - Run all "legacy" tests (i.e. t/tests/legacy-*), which were
         imported from the old test suite.
      * suite:<suite>[,<suite...>]
        - Run all tests in the listed suites.
      * tag:<tag-name>
        - Run any test that lists <tag-name> in "Test-For" or
          "Test-Against".


Test artifacts are cached in <testing-directory> and will be reused if
deemed "up-to-date".  This cache can greatly reduce the run time of the
test suite.
END
    exit($exitcode//2);
}

# Local Variables:
# indent-tabs-mode: nil
# cperl-indent-level: 4
# End:
# vim: syntax=perl sw=4 sts=4 sr et
